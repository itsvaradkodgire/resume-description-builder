{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cc0cc7c-0b32-4f6a-909c-15bf77de30e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490f5ca-fb6b-47d2-b3c1-8250c206117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "techstack=\"Python, SQL, Java, PyTorch, TensorFlow, Scikit-learn, Pandas, NumPy, APIs, Deep learning,machine learning, FastAPI, Generative AI, Hadoop, Spark, PySpark SQL, MySQL, MongoDB, Tableau, Power BI, Excel, RAG, AI Agent, Transformers, RNN, CNN, ANN, vecotr db, html, css, js, jdbc \"\n",
    "aboutme=\"\"\"Education:\n",
    "PG Diploma in Big Data Analytics, CDAC Bangalore (2024–25) – Grade A, 74.38%\n",
    "B.E. in Electronics & Telecommunication, MMCOE Pune (2020–24) – CGPA 7.2\n",
    "Projects:\n",
    "TapVision: AI-powered accessibility tool (Python, Streamlit, gTTS, Google Vision API, NLP).\n",
    "Sentiment Analysis Pipeline: Real-time social media emotion detection (Hadoop, PySpark, MLlib, Twitter API).\n",
    "Autoread Table Flow: Vector search & retrieval system (Graph RAG, LangChain, FAISS, GenAI API, MongoDB).\n",
    "experience: i am fresher so i worked on projects but didnt worked in company so also considerthat facotor but dont mention it in resume just dont fake my experience  \n",
    "\"\"\"\n",
    "jobdescription = input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64591aa4-80da-4272-bc66-1ae680d87d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's your tailored professional description and structured tech stack:\n",
      "\n",
      "### Professional Summary\n",
      "\n",
      "A dedicated Big Data Analytics postgraduate with a robust foundation in Data Science, Machine Learning, and Generative AI. Proven ability to leverage Python (Pandas, NumPy, Scikit-learn) and Big Data technologies (Hadoop, PySpark) for complex data analysis, predictive modeling, and real-time insights. Experienced in building AI-powered solutions, including vector search systems and sentiment analysis pipelines. Eager to apply strong statistical understanding and time-series forecasting to optimize cloud costs and enhance resource reliability for businesses.\n",
      "\n",
      "### Tech Stack\n",
      "\n",
      "*   **Programming Languages:** Python (NumPy, Pandas, Scikit-learn), SQL, Java\n",
      "*   **Machine Learning & AI:** Deep Learning, PyTorch, TensorFlow, Scikit-learn, Transformers, RNN, CNN, ANN, APIs\n",
      "*   **Generative AI & Advanced AI:** Generative AI, RAG (Retrieval-Augmented Generation), AI Agents, LangChain, Prompt Engineering, Vector Databases\n",
      "*   **Data Engineering & Big Data:** Hadoop, Apache Spark, PySpark, PySpark SQL, Spark MLlib\n",
      "*   **Databases:** MySQL, MongoDB, SQL Server, NoSQL\n",
      "*   **Data Analysis & Processing:** Pandas, NumPy, Excel, Data Wrangling, ETL Pipelines, Time-Series Analysis\n",
      "*   **AI Engineering & Deployment:** FastAPI, REST APIs, Model Deployment, MLOps, Docker\n",
      "*   **Visualization & BI:** Matplotlib, Seaborn, Tableau, Power BI\n",
      "*   **Cloud & Tools:** Git, Linux, Google Cloud (GCP) / AWS (basics)\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=\"\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", contents=f\"\"\"job description: {jobdescription} and tech stack: {techstack} and about me {aboutme}\n",
    "You are a professional resume/LinkedIn summary writer. I will provide you with a list of my skills. Your task is to:\n",
    "Write a 90-word professional description of me, tailored for Data Science, AI, ML, Analytics, or Engineering roles.\n",
    "Avoid fluff or filler words.\n",
    "Emphasize how my skills create value for businesses.\n",
    "Write in third person, concise and professional.\n",
    "Ensure the description is ATS-optimized by naturally incorporating relevant keywords.\n",
    "Create a structured Tech Stack section from my provided skills. Expand and logically group them to match industry job descriptions and improve ATS score. Use this structure (and add if needed and remove categories if didnot match job description html css will not be needing in ai ml role):\n",
    "given below is tech stak is all the skill i know but dont include them all just add what are needed for job given in the description\n",
    "Tech Stack\n",
    "Programming Languages: Python, SQL, Java\n",
    "Machine Learning & AI: Scikit-learn, PyTorch, TensorFlow, RNN, CNN, ANN, Transformers, APIs\n",
    "Generative AI & Advanced AI: Generative AI, RAG (Retrieval-Augmented Generation), AI Agents, LangChain, Prompt Engineering\n",
    "Data Engineering & Big Data: Hadoop, PySpark, PySpark SQL, Spark MLlib\n",
    "Databases: MySQL, MongoDB, SQL Server, NoSQL\n",
    "Data Analysis & Processing: Pandas, NumPy, Excel, Data Wrangling, ETL Pipelines\n",
    "AI Engineering & Deployment: Deep Learning, FastAPI, REST APIs, Model Deployment, MLOps\n",
    "Visualization & BI: Tableau, Power BI, Matplotlib, Seaborn\n",
    "Cloud & Tools: Docker, Git, Linux, Google Cloud / AWS basics\n",
    "Ensure the Tech Stack reflects real-world role expectations and clusters related skills together for readability and ATS optimization.\n",
    "\"\"\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63f61bc-5bce-4772-bb3f-73a9d5347810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " sadfsadfsadf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sadfsadfsadf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Programming Languages: Python (NumPy, Pandas, Scikit-learn), SQL, Java\n",
    "Machine Learning & AI: Deep Learning, PyTorch, TensorFlow, Scikit-learn, Transformers, RNN, CNN, ANN, APIs\n",
    "Generative AI & Advanced AI: Generative AI, RAG (Retrieval-Augmented Generation), AI Agents, LangChain, Prompt Engineering, Vector Databases\n",
    "Data Engineering & Big Data: Hadoop, Apache Spark, PySpark, PySpark SQL, Spark MLlib\n",
    "Databases: MySQL, MongoDB, SQL Server, NoSQL\n",
    "Data Analysis & Processing: Pandas, NumPy, Excel, Data Wrangling, ETL Pipelines, Time-Series Analysis\n",
    "AI Engineering & Deployment: FastAPI, REST APIs, Model Deployment, MLOps, Docker\n",
    "Visualization & BI: Matplotlib, Seaborn, Tableau, Power BI\n",
    "Cloud & Tools: Git, Linux, Google Cloud (GCP) / AWS (basics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680431d7-04b6-4364-be4f-711c8d70404d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
